<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title>CME 241: Reinforcement Learning for Stochastic Control Problems in Finance</title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="1671.6">
  <style type="text/css">
    p.p4 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p5 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000e9}
    p.p6 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000; min-height: 12.0px}
    li.li4 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000}
    li.li5 {margin: 0.0px 0.0px 0.0px 0.0px; line-height: 14.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000e9}
    span.s1 {font-kerning: none}
    span.s2 {text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #0000e9}
    span.s3 {font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000}
    span.s4 {-webkit-text-stroke: 0px #000000}
    span.s5 {text-decoration: underline ; font-kerning: none; color: #0000e9}
    span.s6 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #0000e9}
    span.s7 {text-decoration: underline ; font-kerning: none}
    span.s8 {color: #000000; -webkit-text-stroke: 0px #000000}
    table.t1 {border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #6d6d6d #6d6d6d #6d6d6d #6d6d6d}
    td.td1 {width: 71.7px; margin: 0.5px 0.5px 0.5px 0.5px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #6d6d6d #6d6d6d #6d6d6d #6d6d6d; padding: 1.0px 1.0px 1.0px 1.0px}
    td.td2 {width: 125.4px; margin: 0.5px 0.5px 0.5px 0.5px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #6d6d6d #6d6d6d #6d6d6d #6d6d6d; padding: 1.0px 1.0px 1.0px 1.0px}
    td.td3 {width: 235.3px; margin: 0.5px 0.5px 0.5px 0.5px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #6d6d6d #6d6d6d #6d6d6d #6d6d6d; padding: 1.0px 1.0px 1.0px 1.0px}
    td.td4 {width: 308.7px; margin: 0.5px 0.5px 0.5px 0.5px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #6d6d6d #6d6d6d #6d6d6d #6d6d6d; padding: 1.0px 1.0px 1.0px 1.0px}
    td.td5 {width: 681.3px; margin: 0.5px 0.5px 0.5px 0.5px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #6d6d6d #6d6d6d #6d6d6d #6d6d6d; padding: 1.0px 1.0px 1.0px 1.0px}
    ul.ul1 {list-style-type: disc}
    ul.ul2 {list-style-type: circle}
  </style>
</head>
<body>
<h1 style="margin: 0.0px 0.0px 16.1px 0.0px; line-height: 28.0px; font: 24.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Welcome to Winter 2020 edition of CME 241:</b></span></h1>
<h1 style="margin: 0.0px 0.0px 16.1px 0.0px; line-height: 28.0px; font: 24.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Reinforcement Learning for Stochastic Control Problems in Finance</b></span></h1>
<h1 style="margin: 0.0px 0.0px 16.1px 0.0px; line-height: 28.0px; font: 24.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Instructor: </b><a href="mailto:ashwin.rao@stanford.edu"><span class="s2"><b>Ashwin Rao</b></span></a></span></h1>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; line-height: 22.0px; font: 18.0px Times; color: #0000e9; -webkit-text-stroke: #0000e9"><span class="s3"><b>• Classes: Wed &amp; Fri 4:30-5:50pm. </b><a href="https://campus-map.stanford.edu/?srch=380-380W#"><span class="s2"><b>Bldg 380 (Sloan Mathematics Center - Math Corner), Room 380w</b></span></a><b><span class="Apple-converted-space"> </span></b></span></h2>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; line-height: 22.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>• Office Hours: Fri 2-4pm (or by appointment) in ICME M05 (in Huang Engineering Bldg)</b></span></h2>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; line-height: 22.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Grade will be based on</b></span></h2>
<ul class="ul1">
  <li class="li4"><span class="s4"></span><span class="s1">30% Mid-Term Exam (on Theory, Modeling and Algorithms)</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">40% Final Exam (on Theory, Modeling and Algorithms)</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">30% Assignments: Programming, Technical Writing and Theory Problem-Solving (to be done throughout the course)</span></li>
</ul>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; line-height: 22.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Learning Material will be a combination of</b></span></h2>
<ul class="ul1">
  <li class="li5"><span class="s4"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/"><span class="s5">Technical Documents/Lecture Slides I have prepared specifically for this course</span></a></span></li>
  <li class="li5"><span class="s4"><a href="https://github.com/coverdrive/MDP-DP-RL"><span class="s5">Python codebase I have developed for this course</span></a></span><span class="s3"> to help you "learn through coding"</span></li>
  <li class="li5"><span class="s4"><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html"><span class="s5">Slides and Videos from David Silver's UCL course on RL</span></a></span></li>
  <li class="li4"><span class="s4"></span><span class="s1">For deeper self-study and reference, augment the above content with <a href="http://incompleteideas.net/book/the-book-2nd.html"><span class="s6">The Sutton-Barto RL Book and Sutton's accompanying teaching material</span></a></span></li>
</ul>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; line-height: 22.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Lecture-by-Lecture (tentative) schedule with corresponding lecture slides, reading/videos, and assignments</b></span></h2>
<table cellspacing="0" cellpadding="0" class="t1">
  <tbody>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>Date</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p4"><span class="s1"><b>Lecture Slides</b></span></p>
      </td>
      <td valign="middle" class="td3">
        <p class="p4"><span class="s1"><b>Reading/Videos</b></span></p>
      </td>
      <td valign="middle" class="td4">
        <p class="p4"><span class="s1"><b>Suggested Assignments</b></span></p>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 8</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/course_details.pdf"><b>Course Overview</b></a></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>First (Introduction) chapter of Sutton-Barto (pages 1-12)</b></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/rich_sutton_slides/1-admin-and-intro.pdf"><span class="s6"><b>Rich Sutton's corresponding slides on Intro to RL</b></span></a></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/intro_RL.pdf"><span class="s6"><b>David Silver's slides on Intro to RL</b></span></a></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=2pWv7GOvuf0"><span class="s6"><b>David Silver's corresponding video (youtube) on Intro to RL</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Install/Setup on your laptop with LaTeX, Python 3 (and optionally Jupyter notebook)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Create a git repo for this course where you can upload and organize all the code and technical writing you will do as part of assignments and self-learning</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Let the Course Assistant (CA) know of your git repo, so we can periodically review your assignments and other self-learning work</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 10</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/MDP.pdf"><b>Markov Processes (MP) and Markov Reward Processes (MRP)</b></a></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=lfHX2hHRMVQ"><span class="s6"><b>David Silver's corresponding video (on youtube) on MPs/MRPs/MDPs</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write out the MP/MRP definitions and MRP Value Function definition (in LaTeX) in your own style/notation (so you really internalize these concepts)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Think about the data structures/class design (in Python 3) to represent MP/MRP and implement them with clear type declarations</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Remember your data structure/code design must resemble the Mathematical/notational formalism as much as possible</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Specifically the data structure/code design of MRP should be incremental (and not independent) to that of MP<span class="Apple-converted-space"> </span></b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Separately implement the r(s,s') and the R(s) = \sum_{s'} p(s,s') * r(s,s') definitions of MRP</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code to convert/cast the r(s,s') definition of MRP to the R(s) definition of MRP (put some thought into code design here)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code to generate the stationary distribution for an MP</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 15</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/MDP.pdf"><b>Markov Decision Processes (MDP), Value Function, and Bellman Equations</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Third (MDP) chapter of Sutton-Barto book (pages 47-67)</b></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/rich_sutton_slides/5-6-MDPs.pdf"><span class="s6"><b>Rich Sutton's corresponding slides on MDPs</b></span></a></span></li>
          <li class="li5"><span class="s4"><b></b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/mdp_mrp_commute.pdf"><span class="s5"><b>Two ways of arriving at the identical MRP from an MDPRefined (r(s,s',a) definition)</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write the Bellman equation for MRP Value Function and code to calculate MRP Value Function (based on Matrix inversion method you learnt in this lecture)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write out the MDP definition, Policy definition and MDP Value Function definition (in LaTeX) in your own style/notation (so you really internalize these concepts)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Think about the data structure/class design (in Python 3) to represent MDP, Policy, Value Function, and implement them with clear type definitions</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>The data struucture/code design of MDP should be incremental (and not independent) to that of MRP</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Separately implement the r(s,s',a) and R(s,a) = \sum_{s'} p(s,s',a) * r(s,s',a) definitions of MDP</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code to convert/cast the r(s,s',a) definition of MDP to the R(s,a) definition of MDP (put some thought into code design here)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code to create a MRP given a MDP and a Policy</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write out all 8 MDP Bellman Equations and also the transformation from Optimal Action-Value function to Optimal Policy (in LaTeX)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 17</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/DP.pdf"><b>Dynamic Programming Algorithms</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Fourth (Dynamic Programming) chapter of Sutton-Barto book (pages 73-88)</b></span></li>
          <li class="li5"><span class="s4"><b></b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/BellmanOperators.pdf"><span class="s5"><b>Understanding Dynamic Programming through Bellman Operators</b></span></a></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/rich_sutton_slides/7-8-DP.pdf"><span class="s6"><b>Rich Sutton's corresponding slides on Dynamic Programming</b></span></a></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;t=3110s"><span class="s6"><b>David Silver's video (on youtube) on Dynamic Programming</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code for Policy Evaluation (tabular) algorithm</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code for Policy Iteration (tabular) algorithm</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code for Value Iteration (tabular) algorithm</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Those familiar with function approximation (deep networks, or simply linear in featues) can try writing code for the above algorithms with function approximation (a.k.a. Approximate DP)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 22</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/UtilityTheoryForRisk.pdf"><b>Understanding Risk-Aversion through Utility Theory</b></a></span><span class="s3"><b>(as a pre-req to Application Problem 1)<span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional (Related) Reading: </b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/EfficientFrontier.pdf"><span class="s6"><b>A Terse Introduction to Efficient Frontier Mathematics</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Work out (in LaTeX) the equations for Absolute/Relative Risk Premia for CARA/CRRA respectively</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write the solutions to Portfolio Applications covered in class with precise notation (in LaTeX)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 24</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/MertonPortfolio.pdf"><b>Application Problem 1 - Optimal Asset Allocation/Consumption (Merton's 1969 Portfolio Problem)</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional Review: </b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/StochasticCalculusFoundations.pdf"><span class="s6"><b>Stochastic Calculus Foundations</b></span></a><b> (used in setting up HJB)</b></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Reference: </b><a href="https://arxiv.org/pdf/1706.10059.pdf"><span class="s6"><b>A paper on </b><i>A Deep RL Framework for Optimal Asset Allocation</i></span></a></span></li>
          <li class="li5"><span class="s4"><b></b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/DiscreteVSContinuous.pdf"><span class="s5"><b>Some (rough) pointers on Discrete versus Continuous MDPs, and solution techniques</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Model Merton's Portfolio problem as an MDP (write the model in LaTeX)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement this MDP model in code</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Try recovering the closed-form solution with a DP algorithm that you implemented previously</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Model a real-world Portfolio Allocation+Consumption problem as an MDP (including real-world frictions and constraints)</b></span></li>
          <li class="li5"><span class="s4"><b></b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/OptimalAssetAllocationDiscrete.pdf"><span class="s5"><b>Exam Practice Problem: Optimal Asset Allocation in Discrete Time</b></span></a></span><span class="s3"><b> (</b><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/OptimalAssetAllocationDiscreteSolution.pdf"><span class="s6"><b>Solution</b></span></a><b>)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 29</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/AmericanOptionsRL.pdf"><b>Application Problem 2 - Optimal Exercise of American Options</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Reference: </b><a href="https://people.math.ethz.ch/~hjfurrer/teaching/LongstaffSchwartzAmericanOptionsLeastSquareMonteCarlo.pdf"><span class="s6"><b>Longstaff-Schwartz paper on Pricing American Options (industry-standard approach)</b></span></a></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Reference: </b><a href="http://proceedings.mlr.press/v5/li09d/li09d.pdf"><span class="s6"><b>A paper on </b><i>RL for Optimal Exercise of American Options</i></span></a><b><span class="Apple-converted-space"> </span></b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement Black-Scholes formulas for European Call/Put Pricing</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement standard binary tree/grid-based numerical algorithm for American Option Pricing and ensure it validates against Black-Scholes formula for Europeans</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement Longstaff-Schwartz Algorithm and ensure it validates against binary tree/grid-based solution for path-independent options</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Explore/Discuss an Approximate Dynamic Programming solution as an alternative to Longstaff-Schwartz Algorithm</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>January 31</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/OrderExecution.pdf"><b>Application Problem 3 - Optimal Trade Order Execution</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Reference: </b><a href="http://alo.mit.edu/wp-content/uploads/2015/06/Optimal-Control-of-Execution-Costs.pdf"><span class="s6"><b>Bertsimas-Lo paper on Optimal Trade Order Execution</b></span></a><b><span class="Apple-converted-space"> </span></b></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Reference: </b><a href="https://pdfs.semanticscholar.org/3d2d/773983c5201b58586af463f045befae5bbf2.pdf"><span class="s6"><b>Almgren-Chriss paper on Risk-Adjusted Optimal Trade Order Execution</b></span></a><b><span class="Apple-converted-space"> </span></b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Work out (in LaTeX) the solution to the Linear Impact model we covered in class</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Model a real-world Optimal Trade Order Execution problem as an MDP (with complete order book included in the State)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>February 5</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/MC-TD.pdf"><b>Model-free (RL) Prediction With Monte Carlo and Temporal Difference</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=PnHCvfgC_ZA&amp;t=5s"><span class="s6"><b>David Silver's corresponding video (youtube) on Model-free Prediction</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Monte-Carlo and TD (Model-Free) Prediction sections from Sutton-Barto textbook (pages 91-95, 119-128)</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code for the interface for tabular RL algorithms. The core of this interface should be a mapping from a (state, action) pair to a sampling of the (next state, reward) pair. It is important that this interface doesn't present the state-transition probability model or the reward model.</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement any tabular Monte-Carlo algorithm for Value Function prediction</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement tabular 1-step TD algorithm for Value Function prediction</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Test the above implementation of Monte-Carlo and TD Value Function prediction algorithms versus DP Policy Evaluation algorithm on an example MDP</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Prove that fixed learning rate (step size alpha) for MC is equivalent to an exponentially decaying average of episode returns</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>February 7</b></span></p>
      </td>
      <td colspan="3" valign="middle" class="td5">
        <p class="p4"><span class="s1"><b>Midterm Exam</b></span></p>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>February 12</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/MC-TD.pdf"><b>Model-free (RL) Prediction with Eligibility Traces (TD(Lambda))</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=PnHCvfgC_ZA&amp;t=5s"><span class="s6"><b>David Silver's corresponding video (youtube) on Model-free Prediction</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>n-Step TD section of Sutton-Barto textbook (pages 141-145)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: TD(Lambda) and Eligibility Traces-based Prediction is covered on pages 287-297, but this treatment is for the more general case of function approximation of Value Function (we've only covered tabular RL algorithms so far).</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement Forward-View TD(Lambda) algorithm for Value Function Prediction</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement Backward View TD(Lambda), i.e., Eligibility Traces algorithm for Value Function Prediction</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement these algorithms as offline or online algorithms (offline means updates happen only after a full simulation trace, online means updates happen at every time step)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Test these algorithms on some example MDPs, compare them versus DP Policy Evaluation, and plot their accuracy as a function of Lambda</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Prove that Offline Forward-View TD(Lambda) and Offline Backward View TD(Lambda) are equivalent. We covered the proof of Lambda = 1 in class. Do the proof for arbitrary Lambda (similar telescoping argument as done in class) for the case where a state appears only once in an episode.</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>February 14</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/control.pdf"><b>Model-free Control (RL for Optimal Value Function/Policy)</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;t=2713s"><span class="s6"><b>David Silver's corresponding video (youtube) on Model-free Control</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>MC and TD-based Control sections of Sutton-Barto textbook (pages 96-111, 129-134, 146-149)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: SARSA(Lambda) is covered on pages 303-307, but this treatment is for the more general case of function approximation of Value Function (we've only covered tabular RL algorithms so far)</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Prove the Epsilon-Greedy Policy Improvement Theorem (we sketched the proof in Class)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Provide (with clear mathematical notation) the defintion of GLIE (Greedy in the Limit with Infinite Exploration)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement the tabular SARSA and tabular SARSA(Lambda) algorithms</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement the tabular Q-Learning algorithm</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Test the above algorithms on some example MDPs by using DP Policy Iteration/Value Iteration solutions as a benchmark</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>February 19 and 21</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/FA.pdf"><b>RL with Function Approximation (including Deep RL and Batch Methods)</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=UoPei5o4fps&amp;t=2120s"><span class="s6"><b>David Silver's corresponding video (youtube) on RL with Function Approximation</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Function Approximation sections of Sutton-Barto textbook (pages 197-210, 222-230, 243-248)</b></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"><span class="s6"><b>Original DQN paper</b></span></a><b> and </b><a href="https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf"><span class="s6"><b>Nature DQN paper</b></span></a></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="http://www.jmlr.org/papers/volume4/lagoudakis03a/lagoudakis03a.pdf"><span class="s6"><b>Lagoudakis-Parr paper on Least Squares Policy Iteration (LSPI)</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code for the interface for RL algorithms with value function approximation. The core of this interface should be a function from a (state, action) pair to a sampling of the (next state, reward) pair. It is important that this interface doesn't present the state-transition probability model or the reward model.</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement any Monte-Carlo Prediction algorithm with Value Function approximation</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement 1-step TD Prediction algorithm with Value Function approximation</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement Eligibility-Traces-based TD(lambda) Prediction algorithm with Value Function approximation</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement SARSA and SARSA(Lambda) with Value Function approximation</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Implement Q-Learning with Value Function approximation</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: Implement LSTD and LSPI</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Test the above algorithms versus DP Policy Evaluation and DP Policy Iteration/Value Iteration algorithm on an example MDP</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Project Suggestion: Customize the LSPI algorithm for American Option Pricing (see </b><a href="http://proceedings.mlr.press/v5/li09d/li09d.pdf"><span class="s6"><b>this paper</b></span></a><b>)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>February 26 and 28</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/ValueFunctionGeometry.pdf"><b>Value Function Geometry and Gradient TD</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>This week, aim to catch up on all the non-optional reading from previous weeks</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: Those of you who have made more progress on reading can aim to do some of the Optional reading from previous weeks (eg: DQN paper and LSPI paper)</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>This week, aim to catch up on the coding assignments from previous weeks. Aim to do the basic algorithms</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Those of you who have made more progress on coding can try implementing the more advanced algorithms in my suggested assignment work from previous weeks (eg: LSTD/LSPI)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write with proper notation, the derivations to solutions of Linear Systems for Bellman Error-minimization and Projected Bellman Error-minimization (lecture slides have the derivation, but aim to do it yourself)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: Write with proper notation, the derivation of Gradient TD (the last two slides of the lecture have the derivation, but aim to do it yourself)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>March 4</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/PolicyGradient.pdf"><b>Policy Gradient Algorithms</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=KHZVXao4qXs&amp;t=1s"><span class="s6"><b>David Silver's corresponding video (youtube) on Policy Gradient Algorithms</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Policy Gradient chapter of Sutton-Barto textbook (pages 321-332, 335-336)</b></span></li>
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf"><span class="s6"><b>Original Paper on Policy Gradient</b></span></a></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write Proof (with precise notation) of the Policy Gradient Theorem</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Derive the score function for softmax policy (for finite set of actions)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Derive the score function for gaussian policy (for continuous actions)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write code for the REINFORCE Algoithm (Monte-Carlo Policy Gradient Algorithm, i.e., no Critic)</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: Write code for Actor-Critic Policy Gradient Algorithms (with TD(0) and with Eligiblity-Traces-based TD(Lambda))</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Write Proof (with proper notation) of the Compatible Function Approximation Theorem</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Optional: Write code for Natural Policy Gradient Algorithm based on Compatible Linear Function Appeoximation for Critic</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>March 6</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/dyna.pdf"><b>Integrating Learning and Planning</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=ItMutbeOHtc"><span class="s6"><b>David Silver's corresponding video (youtube) on Integrating Learning and Planning</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Chapter of Sutton-Barto textbook on Integrating Learning and Planning (pages 159-188)</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Aim to catch up on the coding assignment of trying to solve the finance problem of your choice with an RL Algorithm</b></span></li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
<p class="p6"><span class="s1"></span><br></p>
<table cellspacing="0" cellpadding="0" class="t1">
  <tbody>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>March 11</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/david_silver_slides/XX.pdf"><b>Exploration versus Exploitation</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li5"><span class="s8"><b></b></span><span class="s3"><b>Optional: </b><a href="https://www.youtube.com/watch?v=sGuiWX07sKw&amp;t=4570s"><span class="s6"><b>David Silver's corresponding video (youtube) on Exploration versus Exploitation</b></span></a></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Chapter of Sutton-Barto textbook on Multi-Armed Bandits (pages 25-41)</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Aim to catch up on the coding assignment of trying to solve the finance problem of your choice with an RL Algorithm</b></span></li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
<p class="p6"><span class="s1"></span><br></p>
<table cellspacing="0" cellpadding="0" class="t1">
  <tbody>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>March 13</b></span></p>
      </td>
      <td valign="middle" class="td2">
        <p class="p5"><span class="s7"><a href="file:///Users/z001xdc/mydocs/technical-documents/finance/cme241/lecture_slides/RetailAI.pdf"><b>Case Study on Planning, Control and Pricing in Real-World Retail Industry</b></a></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></p>
      </td>
      <td valign="middle" class="td3">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Review all of the course material to prepare for the Final Exam</b></span></li>
        </ul>
      </td>
      <td valign="middle" class="td4">
        <ul class="ul1">
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Upload all of your assignment work on the github account you had created at the start of the course</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Inform the Course Assistant that you have uploaded all of your work</b></span></li>
          <li class="li4"><span class="s4"><b></b></span><span class="s1"><b>Ensure that all of your assignment work can be accessed by the Course Assistant at github.com (make sure you have pushed and not just commited)</b></span></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="middle" class="td1">
        <p class="p4"><span class="s1"><b>Week of March 16-20</b></span></p>
      </td>
      <td colspan="3" valign="middle" class="td5">
        <p class="p4"><span class="s1"><b>Final Exam</b></span></p>
      </td>
    </tr>
  </tbody>
</table>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; line-height: 22.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000"><span class="s1"><b>Purpose and Grading of Assignments</b></span></h2>
<ul class="ul1">
  <li class="li4"><span class="s4"></span><span class="s1">Assignments are not to be treated as "tests/exams" with a right/wrong answer</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">Rather, they should be treated as part of your learning experience</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">You will TRULY understand ideas/models/algorithms only when you WRITE down the Mathematics and the Code precisely</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">In other words, simply reading the Mathematics or the Code gives you a false sense of understanding things</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">Take the initiative to make up your own assignments, especially on topics you feel you don't quite understand</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">Individual assignments won't get a grade and there are no due dates for the assignments</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">Rather, the entire body of assignments work throughout the course will be graded (upload regularly on your course git repo)</span></li>
  <li class="li4"><span class="s4"></span><span class="s1">It will be graded less on correctness and completeness, and more on:</span></li>
  <ul class="ul2">
    <li class="li4"><span class="s4"></span><span class="s1">Coding and Technical Writing style that is clear and modular</span></li>
    <li class="li4"><span class="s4"></span><span class="s1">Demonstration of curiosity and commitment to learning through the overall body of assignments work</span></li>
    <li class="li4"><span class="s4"></span><span class="s1">Extent of engagement in asking questions and seeking feedback for improvements</span></li>
  </ul>
</ul>
</body>
</html>
