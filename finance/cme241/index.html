<!DOCTYPE html>
<html>
<head>
<style>
th {
	text-align: left;
}
</style>
<title>CME 241: Reinforcement Learning for Stochastic Control Problems in Finance </title>
</head>

<body>
<h1>Welcome to CME 241: Reinforcement Learning for Stochastic Control Problems in Finance</h1>
<h1>Instructor: <a href="mailto:ashwin.rao@stanford.edu">Ashwin Rao</a></h1>
<h2>Winter 2019 Classes: Wed & Fri 4:30pm - 5:50pm. <a href="https://campus-map.stanford.edu/?srch=200-203">Bldg 200 (Lane History Corner), Room 203</a>
<h2>Ashwin's Office Hours: Fri 2:00pm - 4:00pm (or by appointment) in ICME M09 (Ashwin's office room)</h2>	
<h2>Questions/Discussions on <a href="https://piazza.com/stanford/winter2019/cme241/home">Piazza</a>, Course Assistant (CA): <a href="mailto:jeffgu@stanford.edu">Jeffrey Gu</a>.</h2>
<h2>Course Overview</h2>
<ul>
<li>Theory of Markov Decision Processes (MDP)</li>
<li>Dynamic Programming (DP) Algorithms</li>
<li>Reinforcement Learning (RL) Algorithms</li>
<li>We will model and apply these algorithms to 3 Financial/Trading problems:
<ul>
<li>(Dynamic) Asset-Allocation to maximize <em>Utility of Consumption</em></li>
<li>Optimal Exercise/Stopping of Path-dependent American Options</li>
<li> Optimal Trade Order Execution (managing <em>Price Impact</em>)</li>
</ul>
</li>
<li>By treating each of these problems as MDPs (i.e., Stochastic Control)</li>
<li>We will first go over classical/analytical solutions to these problems (in simple settings)</li>
<li>Then we will introduce real-world considerations, and tackle with RL (or DP)</li>
<li>Emphasis on Python implementations of these models and algorithms</li>
<li>More details on the course contents <a href="course_details.pdf">here</a></li>
</ul>
<h2>(Light) Pre-requisites</h2>
<ul>
<li> <strong>Required</strong>: Undergraduate-level background in Applied Mathematics, especially in Linear Algebra, Probability Theory and Optimization</li>
<li> <strong>Required</strong>: Background in Data Structures & Algorithms, with programming experience in numpy/scipy</li>
<li> <strong>Recommended</strong>: Basic background in Pricing and Portfolio Theory, although we will do an overview of the requisite Finance/Economics</li>
<li> <strong>Not required</strong>: MDP, DP, RL (we will cover these topics from scratch)</li>
</ul>
<h2>Grade will be based on</h2>
<ul>
	<li>25% Mid-Term Exam (on Theory, Modeling and Algorithms)</li>
	<li>40% Final Exam (on Theory, Modeling and Algorithms)</li>
	<li>35% Assignments: Programming, Technical Writing and Theory Problem-Solving (to be done throughout the course)</li>
</ul>
<h2>Purpose and Grading of Assignments</h2>
<ul>
	<li>Assignments are not to be treated as "tests/exams" with a right/wrong answer</li>
	<li>Rather, they should be treated as part of your learning experience</li>
	<li>You will TRULY understand ideas/models/algorithms only when you WRITE down the Mathematics and the Code precisely</li>
	<li>In other words, simply reading the Mathematics or the Code gives you a false sense of understanding things</li>
	<li>Take the initiative to make up your own assignments, especially on topics you feel you don't quite understand</li>
	<li>Individual assignments won't get a grade and there are no due dates for the assignments</li>
	<li>Rather, the entire body of assignments work throughout the course will be graded (upload regularly on your course git repo)</li>
	<li>It will be graded less on correctness and completeness, and more on:
		<ul>
			<li>Coding and Technical Writing style that is clear and modular</li>
			<li>Demonstration of curiosity and commitment to learning through the overall body of assignments work</li>
			<li>Extent of engagement in asking questions and seeking feedback for improvements</li>
		</ul>
	</li>
</ul>
<h2>Learning Material will be a combination of</h2>
<ul>
	<li><a href="lecture_slides/">Technical Documents/Lecture Slides I have prepared specifically for this course</a></li>
	<li><a href="https://github.com/coverdrive/MDP-DP-RL">Python codebase I have developed for this course</a> to help you "learn through coding"</li>
	<li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">Slides and Videos from David Silver's UCL course on RL</a></li>
	<li>For deeper self-study and reference, augment the above content with <a href="http://incompleteideas.net/book/the-book-2nd.html">The Sutton-Barto RL Book and Sutton's accompanying teaching material</a></li>
</ul>

<h2>Lecture-by-Lecture (tentative) schedule with corresponding lecture slides, reading/videos, and assignments</h2>
<table border="1">
  <tr>
    <th>Date</th>
    <th>Lecture Slides</th>
    <th>Reading</th>
    <th>Assignments</th>
  </tr>
  <tr>
    <th>January 9</th>
    <th><a href="course_details.pdf">Course Overview</a></th>
    <th>
	    <ul>
		    <li>First (Introduction) chapter of Sutton-Barto (pages 1-12)</li>
		    <li><a href="lecture_slides/rich_sutton_slides/1-admin-and-intro.pdf">Rich Sutton's corresponding slides on Intro to RL</a></li>
		    <li>Optional: <a href="lecture_slides/david_silver_slides/intro_RL.pdf">David Silver's slides on Intro to RL</a></li>
		    <li>Optional: <a href="https://www.youtube.com/watch?v=2pWv7GOvuf0">David Silver's corresponding video (youtube) on Intro to RL</a></li>
	    </ul>
    </th>
    <th>
    	<ul>
				<li>Install/Setup on your laptop with LaTeX, Python 3 (and optionally Jupyter notebook)</li>
				<li>Create a git repo for this course where you can upload and organize all the code and technical writing you will do as part of assignments and self-learning</li>
				<li>Let the Course Assistant (CA) know of your git repo, so we can periodically review your assignments and other self-learning work</li>
		</ul>
	</th>
  </tr>
  <tr>
    <th>January 11</th>
    <th><a href="lecture_slides/david_silver_slides/MDP.pdf">Markov Decision Processes</a></th>
    <th>
    	<ul>
		<li>Third (MDP) chapter of Sutton-Barto book (pages 47-67)</li>
		<li>Optional: <a href="lecture_slides/rich_sutton_slides/5-6-MDPs.pdf">Rich Sutton's corresponding slides on MDPs</a></li>
		<li>Optional: <a href="https://www.youtube.com/watch?v=lfHX2hHRMVQ">David Silver's corresponding video (on youtube) on MDPs</a></li>
	</ul>
    </th>
    <th>
			<ul>
				<li>Write out the MP/MRP/MDP/Value Function definitions (in LaTeX) in your own style/notation (so you really internalize these concepts)</li>
				<li>Think about the data structures/class design (in Python 3) to represent MP/MRP/MDPs/Policies and implement them with clear type declarations</li>
				<li>Remember your data structure/code design must resemble the Mathematical/notational formalism as much as possible</li>
				<li>Separately implement the r(s,s') and the R(s) = \sum_{s'} p(s,s') r(s,s') definitions of MRP (likewise for MDP)</li>
				<li>Write code to convert/cast the former definition of MRP/MDP to the latter definition (put some thought into code design here)</li>
				<li>Write code to implement several key transformations/calculations you learnt in this lecture, eg:</li>
				<ul>
					<li>Generate the stationary distribution for an MP</li>
					<li>Create a MRP from an MDP and a (stochastic) Policy</li>
					<li>Calculate the Value function for an MRP that you learnt in this lecture (matrix inversion-based)</li>
				</ul>
			</ul>
    </th>
  </tr>
  <tr>
    <th>January 16</th>
    <th>
    	<a href="lecture_slides/david_silver_slides/MDP.pdf">Bellman Equations</a>
    </th>
    <th>
    	
    </th>
    <th>
    	<ul>
			<li>Write out all 8 Bellman Equations and also the transformation from Optimal Action-Value function to Optimal Policy (in LaTeX)</li>
			<li>Write code corresponding to the above equations</li>
		</ul>
    </th>
  </tr>
  <tr>
    <th>January 18</th>
    <th>
    	<a href="lecture_slides/david_silver_slides/DP.pdf">Dynamic Programming Algorithms</a>
    </th>
    <th>
    	<ul>
		<li>Fourth (Dynamic Programming) chapter of Sutton-Barto book</li>
		<li>Optional: <a href="lecture_slides/rich_sutton_slides/7-8-DP.pdf">Rich Sutton's corresponding slides on Dynamic Programming</a></li>
        	<li>Optional: <a href="https://www.youtube.com/watch?v=Nd1-UUMVfz4&t=3110s">David Silver's video (on youtube) on Dynamic Programming</a></li>
	</ul>
    </th>
    <th>
    	<li>Write code for Dynamic Programming Algorithms (Policy Iteration, Value Iteration) and Approximate Dynamic Programming Algorithms</li>
    </th>
  </tr>
  <tr>
    <th>January 23</th>
    <th>
    	<a href="lecture_slides/UtilityTheoryForRisk.pdf">Understanding Risk-Aversion through Utility Theory</a>(as a pre-req to Application Problem 1)
    </th>
    <th>
    	<ul>
			<li>Optional (Related) reading: <a href="lecture_slides/EfficientFrontier.pdf">A Terse Introduction to Efficient Frontier Mathematics</a></li>
	    </ul>
    </th>
    <th>
    	<ul>
			<li>Work out (in LaTeX) the equations for Absolute/Relative Risk Premia for CARA/CRRA respectively</li>
			<li>Write the Portfolio application problem statement and solution with precise notation (in LaTeX)</li> 
		</ul>
    </th>
  </tr>
  <tr>
    <th>January 25</th>
    <th>
    	<a href="lecture_slides/MertonPortfolio.pdf">Application Problem 1 - Optimal Asset Allocation/Consumption (Merton's 1969 Portfolio Problem)</a>
    </th>
    <th>
    	<ul>
			<li>Reading: <a href="lecture_slides/PortfolioOptNotes.pdf">Discrete-time CARA example</a></li>
			<li>Optional Reading: <a href="lecture_slides/StochasticCalculusFoundations.pdf">Stochastic Calculus Foundations</a> (used in setting up HJB)</li>
		</ul>
    </th>
    <th>
    	<ul>
			<li>Model Merton's Portfolio problem as an MDP (write the model in LaTeX)</li>
			<li>Implement this MDP model in code</li>
			<li>Try recovering the closed-form solution with a DP algorithm that you implemented previously</li>
		</ul>
    </th>
  </tr>
  <tr>
    <th>January 30</th>
    <th>
    	Application Problem 1 - Optimal Asset Allocation/Consumption (Discussion on Real-World modeling and coding)
    </th>
    <th>
    	
    </th>
    <th>
    	
    </th>
  </tr>
  <tr>
    <th>February 1</th>
    <th>
    	<a href="lecture_slides/AmericanOptionsRL.pdf">Application Problem 2 - Optimal Exercise of American Options</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>February 6</th>
    <th>
    	<a href="lecture_slides/OrderExecution.pdf">Application Problem 3 - Optimal Trade Order Execution</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>February 8</th>
    <th colspan="3">Midterm Exam</th>
  </tr>
  <tr>
    <th>February 13 and 15</th>
    <th>
    	 <a href="lecture_slides/david_silver_slides/MC-TD.pdf">Model-free Prediction (RL for Value Function Estimation)</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>February 20 and 22</th>
    <th>
    	<a href="lecture_slides/david_silver_slides/control.pdf">Model-free Control (RL for Optimal Value Function/Policy)</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>February 27 and March 1</th>
    <th>
    	<a href="lecture_slides/david_silver_slides/FA.pdf">RL with Function Approximation (including Deep RL)</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>March 6 and March 8</th>
    <th>
    	<a href="lecture_slides/ValueFunctionGeometry.pdf">Batch Methods (DQN, LSTDQ/LSPI), and Gradient TD</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>March 13 and March 15</th>
    <th>
    	<a href="lecture_slides/PolicyGradient.pdf">Policy Gradient Algorithms</a>
    </th>
    <th></th>
    <th></th>
  </tr>
  <tr>
    <th>March 22 (3:30pm-6:30pm)</th>
    <th colspan="3">Final Exam</th>
  </tr>
</table>
<h2>Learning Tenets</h2>
<ul>
	<li>When learning Theory, blend notational rigor with intuitive understanding</li>
	<li>Write down the mathematical formalism of the lecture contents with great precision (without refering to how I've written them)</li>
	<li>Always start with a simple model/simple algorithm and be clear about why you might want to use a more complex model/algorithm</li>
	<li>Programming is a powerful tool to grasp mathematical concepts (code all ideas/models/algorithms with the aim to visualize as well as validate mathematical properties)</li>
	<li>Code clarity and modularity are important (leverage Object-Oriented and Functional Programming paradigms, and define Types clearly)</li>
	<li>Important to recognize and then model various frictions encountered in real-world trading</li>
	<li>Discuss the ideas you learn with other students, with the CA, and with me. Question everything!</li>
	<li>Recognize that this is an introductory course. Learn the foundations slowly and thoroughly, before graduating to advanced RL (other courses we offer at Stanford)</li>
</ul>
</body>
</html>
